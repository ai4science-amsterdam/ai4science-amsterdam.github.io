---
layout: page-fullwidth 
show_meta: false
title: "AI4Science Colloquium"
#subheadline: "Welcome to our lab."
#teaser: "Hi, welcome to our lab."
header:
   image_fullwidth: "banner.jpg"
   title: ''
   caption: "Credits: Mike Mackenzie"
   caption_url: https://www.flickr.com/photos/mikemacmarketing/30212411048
permalink: "/colloquium/"
---
> Knowledge Shared = Knowledge<sup>2</sup>


The AI4Science Colloquium is a bi-weekly colloquium series, held on alternating Tuesdays at 14:00 Central European Time. In this colloquium our very own Teodora Pandeva and Fiona Lippert invite renowned speakers to present and discuss their state-of-the-art AI solutions for scientific discovery. Interested? Subscribe to our Email-list to be notified.

## Email List
To stay up to date with our activities and be invited to our biweekly AI4Science colloquium series, you may send a request to be included in our emaillist via [an email to us][9] with your name, affiliation and a one-sentence motivation for joining.

## Next Colloquium

#### Catalogue curation, likelihood misspecification & dataset shift: challenges for Bayesian deep-learning in radio astronomy

Date: 29-03-2022 14:00-1500 Central European Summer time


 <img src="../people/AnnaScaife.jpeg"
     alt="AnnaScaife"
     width="100"
     style="float: right; margin-right: 10px; border-radius:50%;" />

Speaker: **Anna Scaife**, Professor of Radio Astronomy at the University of Manchester and Head of the Jodrell Bank Centre for Astrophysics Interferometry Centre of Excellence

**Abstract:** <br/>

Understanding the selection biases introduced by AI models in scientific analysis and extracting well-calibrated uncertainties on machine learning outputs are two key challenges facing the systematic use of such algorithms in radio astronomy. I this talk I will discuss our recent work on uncertainty calibration for radio galaxy classification including how the use of group-equivariant convolutions can correct effects of bias in model outputs, as well as how data curation in astronomy catalogues can cause likelihood misspecification in Bayesian deep-learning. I will go on to talk about how the effect of data curation can also affect the use of semi-supervised learning that leverages large unlabelled datasets - highly relevant for radio astronomy applications where the volume of labelled catalogue data is small, but the quantity of archival survey data is large.

**Bio:** <br/>
Anna is currently Professor of Radio Astronomy at Jodrell Bank Centre for Astrophysics and academic Co-Director of Policy@Manchester at the University of Manchester. Previously she has worked at the University of Southampton (UK), the Dublin Institute for Advanced Studies (Ireland) and the University of Cambridge (UK). She has a PhD from the University of Cambridge and an undergraduate degree from the University of Bristol. [https://www.turing.ac.uk/people/researchers/anna-scaife][10]

## Schedule

- 18 January 2022 - **Andrew Ferguson**
- 7 February 2022 - **Jan-Matthis Lückmann** 
- 1 March 2022 - **Martin van Hecke**
- 15 March 2022 - **Rajesh Ranganath**
- 29 March 2022 - **Anna Scaife**
- 12 April 2022 - **Gabriel Vivó-Truyols**
- 26 April 2022 - **Maximilian Dax**
- 24 May 2022 - **Francesca Grisoni**


## Previous Colloquium

#### Title: Interpretability and Out of Distribution Generalization in Deep Predictive Models
Date: 15-03-2022 16:00-1700 Central European Winter time


 <img src="../people/RajeshRanganath.jpeg"
     alt="RajashRanganath"
     width="100"
     style="float: right; margin-right: 10px; border-radius:50%;" />

Speaker: **Rajesh Ranganath**, NYU

**Abstract:** <br/>

Interpretability enriches what can be gleaned from a good predictive
model. Techniques that learn-to-explain have arisen because they
require only a single evaluation of a model to provide an
interpretation. In the first part of this talk, I will discuss a flaw
with several methods that learn-to-explain: the optimal explainer
makes the prediction rather than highlighting the inputs that are
useful for prediction. I will also describe an evaluation technique
that can detect when the explainer makes the prediction along with a
new method that learns-to-explain without this issue.
In the second part of my talk, I will discuss our work on
representation learning for out of distribution generalization. I will
construct a family of representations that generalize when under
changing  nuisance-induced spurious correlations and have applications
to images and chest X-rays. I will show how nuisance variables can be
constructed using limited prior knowledge and augmentations of the input.

Bio:
Rajesh Ranganath is an assistant professor at NYU's Courant Institute
of Mathematical Sciences and the Center for Data Science. He is also
affiliate faculty at the Department of Population Health at NYUMC. His
research focuses on approximate inference, causal inference,
probabilistic models,  and machine learning for healthcare. Rajesh
completed his PhD at Princeton and BS and MS from Stanford University.
Rajesh has won several awards including the NDSEG graduate fellowship,
the Porter Ogden Jacobus Fellowship, given to the top four doctoral
students at Princeton University, and the Savage Award in Theory and
Methods.

This meeting was not recorded.

<!---
<a class="radius button small" href="https://drive.google.com/file/d/1PryMUuxAw09Flpfa9J0Z7m4cQexa3Q5G/view?usp=sharing">Watch Back ›</a>
-->

For an overview of more  previous colloquia, please have a look at out [blog][2].

[1]: https://bereau.group/
[2]: /blog/
[9]: /contact/
[3]:https://github.com/undark-lab/swyft
[4]:https://arxiv.org/abs/2011.13951
[5]:http://www.mathben.com/
[6]:https://pubs.acs.org/doi/10.1021/acs.jctc.0c00981
[7]:https://github.com/Ensing-Laboratory/FABULOUS
[8]:www.evozyne.com
[10]:https://www.turing.ac.uk/people/researchers/anna-scaife
