I"Q<blockquote>
  <p>Knowledge Shared = Knowledge<sup>2</sup></p>
</blockquote>

<h2 id="next-colloquium">Next Colloquium</h2>

<h3 id="title-permutation-equivariant-neural-networks-for-molecular-generation">Title: Permutation-Equivariant neural networks for Molecular Generation</h3>

<p>Date: 15-09-2020 14:00-15:00 Central European Summer Time</p>

<!--
 <img src="../people/tristan_bereau.jpg"
     alt="Tristan Bereau"
     width="100"
     style="float: right; margin-right: 10px; border-radius:50%;" />
-->

<p>Speaker: <strong>Erik Henning Thiede</strong>, Research Fellow, Flatiron Institute, University of Chicago</p>

<p><strong>Abstract:</strong> <br />
In the last five years, neural networks have emerged as a dominant paradigm for constructing generative models of images and sound data. However, challenges remain when building generative models for molecules. Since molecules are made of collections of indistinguishable particles, they are symmetric to permutation, a symmetry not respected by basic neural network architectures. While neural networks have been constructed that obey permutation symmetry using message-passing ideas, these architectures rely on knowing the molecular structure in advance, limiting their use for generative models.
Here, we introduce a new approach that constructs molecular graphs using permutation-equivariant layers formed by convolutions over the group of permutations. Using these layers, we are able to construct a variational autoencoder that preserves permutational symmetry from input to output. This allows for direct comparison of the inputs to the outputs, avoiding the requirement to solve a potentially costly graph matching problem. Our architecture is able to achieve results comparable to other competing architectures using considerably less domain knowledge.</p>

<!--
<img src="../images/physml.jpg"
     alt="Physical Machine learning"
     width="400"
     style="float: center; margin-right: 10px;"/>
<p>Ref: <a href="https://aip.scitation.org/doi/10.1063/1.5009502">Journal of Chemical Physics</a></p>
-->

<h2 id="email-list">Email List</h2>
<p>To stay up to date with our activities and be invited to our biweekly AI4Science colloquium series, you may send a request to be included in our emaillist via <a href="/contact/">an email to us</a> with your name, affiliation and a one-sentence motivation for joining.</p>

<h2 id="previous-colloquia">Previous Colloquia</h2>

<h4 id="title--physically-motivated-machine-learning-for-multiscale-molecular-simulations">Title:  Physically-motivated machine learning for multiscale molecular simulations</h4>

<p>Date: 30-06-2020 14:00-15:00 Central European Summer Time</p>

<p><img src="../people/tristan_bereau.jpg" alt="Tristan Bereau" width="100" style="float: right; margin-right: 10px; border-radius:50%;" /></p>

<p>Speaker: <strong>Tristan Bereau</strong>, Assistant professor, <a href="https://bereau.group/">Computational Soft Matter</a>, HIMS &amp; IvI, UvA</p>

<p><strong>Abstract:</strong> <br />
Advanced statistical methods are rapidly impregnating many scientific fields, offering new perspectives on long-standing problems. In materials science, data-driven methods are already bearing fruit in various disciplines, such as hard condensed matter or inorganic chemistry, as well as soft matter to a smaller extent.
When coupling machine learning to molecular simulations, many problems of interest display dauntingly-large interpolation spaces, limiting their immediate application without undesired artifacts (e.g., extrapolation). The incorporation of physical information, such as conserved quantities, symmetries, and constraints, can play a decisive role in reducing the interpolation space. Conversely, physics can help determine whether a machine-learning prediction should be trusted, acting as a more robust alternative to the predictive variance.
In this talk I will show how incorporating physics in machine-learning models can help connect resolutions in multiscale modeling. Illustrations will include force-field parametrization, automated dimensionality reduction and clustering, and generative models to reintroduce atomistic detail in coarse-grained configurations.</p>

<p><img src="../images/physml.jpg" alt="Physical Machine learning" width="400" style="float: center; margin-right: 10px;" /></p>
<p>Ref: <a href="https://aip.scitation.org/doi/10.1063/1.5009502">Journal of Chemical Physics</a></p>

<p><a class="radius button small" href="https://drive.google.com/file/d/1COEnlxyiJ0lKjbQ1TqW2xu8CEYVKS0NP/view">Watch Back â€º</a></p>

<p>For an overview of previous colloquia, please have a look at out <a href="/blog/">blog</a>.</p>

:ET