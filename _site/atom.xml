<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="//assets/xslt/atom.xslt" ?>
<?xml-stylesheet type="text/css" href="//assets/css/atom.css" ?>
<feed xmlns="http://www.w3.org/2005/Atom">
	<id>https://ai4science-amsterdam.github.io//</id>
	<title>AI4Science Lab</title>
	<updated>2022-03-31T09:43:25+02:00</updated>

	<subtitle>The AI4Science Lab is an initiative supported by the Faculty of Science (FNWI) at the University of Amsterdam and located in the Informatics Institute (IvI). The AI4Science Lab is also connected to AMLAB, the Amsterdam Machine Learning Lab.
We develop and use machine learning techniques to discover patterns in data streams produced by experiments in a wide variety of scientific fields, ranging from ecology to molecular biology and from chemistry to astrophysics.</subtitle>

	
		
		<author>
			
				<name>Jim Boelrijk</name>
			
			
			
		</author>
	

	<link href="https://ai4science-amsterdam.github.io//atom.xml" rel="self" type="application/rss+xml" />
	<link href="https://ai4science-amsterdam.github.io//" rel="alternate" type="text/html" />

	<generator uri="http://jekyllrb.com" version="4.2.0">Jekyll</generator>

	
		<entry>
			<id>https://ai4science-amsterdam.github.io//colloquium/anna-scaife/</id>
			<title>Anna Scaife</title>
			<link href="https://ai4science-amsterdam.github.io//colloquium/anna-scaife/" rel="alternate" type="text/html" title="Anna Scaife" />
			<updated>2022-03-29T00:00:00+02:00</updated>

			
				
				<author>
					
						<name>Jim Boelrijk</name>
					
					
					
				</author>
			
			<summary>Catalogue curation, likelihood misspecification and dataset shift: challenges for Bayesian deep-learning in radio astronomy</summary>
			<content type="html" xml:base="https://ai4science-amsterdam.github.io//colloquium/anna-scaife/">&lt;h4 id=&quot;catalogue-curation-likelihood-misspecification-and-dataset-shift-challenges-for-bayesian-deep-learning-in-radio-astronomy&quot;&gt;Catalogue curation, likelihood misspecification and dataset shift: challenges for Bayesian deep-learning in radio astronomy&lt;/h4&gt;

&lt;p&gt;Date: 29-03-2022 14:00-1500 Central European Summer time&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../people/AnnaScaife.jpeg&quot; alt=&quot;AnnaScaife&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Anna Scaife&lt;/strong&gt;, Professor of Radio Astronomy at the University of Manchester and Head of the Jodrell Bank Centre for Astrophysics Interferometry Centre of Excellence&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Understanding the selection biases introduced by AI models in scientific analysis and extracting well-calibrated uncertainties on machine learning outputs are two key challenges facing the systematic use of such algorithms in radio astronomy. I this talk I will discuss our recent work on uncertainty calibration for radio galaxy classification including how the use of group-equivariant convolutions can correct effects of bias in model outputs, as well as how data curation in astronomy catalogues can cause likelihood misspecification in Bayesian deep-learning. I will go on to talk about how the effect of data curation can also affect the use of semi-supervised learning that leverages large unlabelled datasets - highly relevant for radio astronomy applications where the volume of labelled catalogue data is small, but the quantity of archival survey data is large.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt;&lt;br /&gt;
Anna is currently Professor of Radio Astronomy at Jodrell Bank Centre for Astrophysics and academic Co-Director of Policy@Manchester at the University of Manchester. Previously she has worked at the University of Southampton (UK), the Dublin Institute for Advanced Studies (Ireland) and the University of Cambridge (UK). She has a PhD from the University of Cambridge and an undergraduate degree from the University of Bristol.&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;radius button small&quot; href=&quot;https://drive.google.com/file/d/11usK-95DvkjC7WG7IyzdQnh2hTd2KmuG/view?usp=sharing&quot;&gt;Watch Back ›&lt;/a&gt;&lt;/p&gt;

</content>

			
				<category term="colloquium" />
			
			
				<category term="colloquium" />
			

			<published>2022-03-29T00:00:00+02:00</published>
		</entry>
	
		<entry>
			<id>https://ai4science-amsterdam.github.io//colloquium/rajesh-ranganath/</id>
			<title>Rajesh Ranganath</title>
			<link href="https://ai4science-amsterdam.github.io//colloquium/rajesh-ranganath/" rel="alternate" type="text/html" title="Rajesh Ranganath" />
			<updated>2022-03-15T00:00:00+01:00</updated>

			
				
				<author>
					
						<name>Jim Boelrijk</name>
					
					
					
				</author>
			
			<summary>Interpretability and Out of Distribution Generalization in Deep Predictive Models</summary>
			<content type="html" xml:base="https://ai4science-amsterdam.github.io//colloquium/rajesh-ranganath/">&lt;h4 id=&quot;interpretability-and-out-of-distribution-generalization-in-deep-predictive-models&quot;&gt;Interpretability and Out of Distribution Generalization in Deep Predictive Models&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;../../people/RajeshRanganath.jpeg&quot; alt=&quot;MartinVanHecke&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Rajesh Ranganath&lt;/strong&gt;, NYU&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Interpretability enriches what can be gleaned from a good predictive
model. Techniques that learn-to-explain have arisen because they
require only a single evaluation of a model to provide an
interpretation. In the first part of this talk, I will discuss a flaw
with several methods that learn-to-explain: the optimal explainer
makes the prediction rather than highlighting the inputs that are
useful for prediction. I will also describe an evaluation technique
that can detect when the explainer makes the prediction along with a
new method that learns-to-explain without this issue.
In the second part of my talk, I will discuss our work on
representation learning for out of distribution generalization. I will
construct a family of representations that generalize when under
changing  nuisance-induced spurious correlations and have applications
to images and chest X-rays. I will show how nuisance variables can be
constructed using limited prior knowledge and augmentations of the input.&lt;/p&gt;

&lt;p&gt;Bio:
Rajesh Ranganath is an assistant professor at NYU’s Courant Institute
of Mathematical Sciences and the Center for Data Science. He is also
affiliate faculty at the Department of Population Health at NYUMC. His
research focuses on approximate inference, causal inference,
probabilistic models,  and machine learning for healthcare. Rajesh
completed his PhD at Princeton and BS and MS from Stanford University.
Rajesh has won several awards including the NDSEG graduate fellowship,
the Porter Ogden Jacobus Fellowship, given to the top four doctoral
students at Princeton University, and the Savage Award in Theory and
Methods.&lt;/p&gt;

&lt;p&gt;This meeting was not recorded.
&lt;!---
&lt;a class=&quot;radius button small&quot; href=&quot;https://drive.google.com/file/d/1PryMUuxAw09Flpfa9J0Z7m4cQexa3Q5G/view?usp=sharing&quot;&gt;Watch Back ›&lt;/a&gt;
--&gt;&lt;/p&gt;

</content>

			
				<category term="colloquium" />
			
			
				<category term="colloquium" />
			

			<published>2022-03-15T00:00:00+01:00</published>
		</entry>
	
		<entry>
			<id>https://ai4science-amsterdam.github.io//colloquium/martin-van-hecke/</id>
			<title>Martin van Hecke</title>
			<link href="https://ai4science-amsterdam.github.io//colloquium/martin-van-hecke/" rel="alternate" type="text/html" title="Martin van Hecke" />
			<updated>2022-03-01T00:00:00+01:00</updated>

			
				
				<author>
					
						<name>Jim Boelrijk</name>
					
					
					
				</author>
			
			<summary>Machine Learning of Combinatiorial Rules in Mechanical Metamaterials</summary>
			<content type="html" xml:base="https://ai4science-amsterdam.github.io//colloquium/martin-van-hecke/">&lt;h4 id=&quot;machine-learning-of-combinatorial-rules-in-mechanical-metamaterials&quot;&gt;Machine Learning of Combinatorial Rules in Mechanical Metamaterials&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;../../people/MartinVanHecke.jpeg&quot; alt=&quot;MartinVanHecke&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Martin van Hecke&lt;/strong&gt;, Leiden University&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Combinatorial problems arising in puzzles, origami, and (meta)material design have rare sets of
solutions, which define complex and sharply delineated boundaries in configuration space. These
boundaries are difficult to capture with conventional statistical and numerical methods. Here we
show that convolutional neural networks can learn to recognize these boundaries, down to finest de-
tail, despite using heavily undersampled training sets, and can successfully generalize. This suggests
that the network infers the underlying combinatorial rules from the sparse training set, opening up
new possibilities for complex design of (meta)materials.&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;radius button small&quot; href=&quot;https://drive.google.com/file/d/1PryMUuxAw09Flpfa9J0Z7m4cQexa3Q5G/view?usp=sharing&quot;&gt;Watch Back ›&lt;/a&gt;&lt;/p&gt;

</content>

			
				<category term="colloquium" />
			
			
				<category term="colloquium" />
			

			<published>2022-03-01T00:00:00+01:00</published>
		</entry>
	
		<entry>
			<id>https://ai4science-amsterdam.github.io//colloquium/jan-matthis-luckmann/</id>
			<title>Jan-Matthis Lückmann</title>
			<link href="https://ai4science-amsterdam.github.io//colloquium/jan-matthis-luckmann/" rel="alternate" type="text/html" title="Jan-Matthis Lückmann" />
			<updated>2022-02-07T00:00:00+01:00</updated>

			
				
				<author>
					
						<name>Jim Boelrijk</name>
					
					
					
				</author>
			
			<summary>Simulation-Based Inference for Neuroscience and Beyond</summary>
			<content type="html" xml:base="https://ai4science-amsterdam.github.io//colloquium/jan-matthis-luckmann/">&lt;h4 id=&quot;simulation-based-inference-for-neuroscience-and-beyond&quot;&gt;Simulation-Based Inference for Neuroscience and Beyond&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;../../people/JanMatthisLuckmann.jpeg&quot; alt=&quot;JanMatthisLuckmann&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Jan-Matthis Lückmann&lt;/strong&gt; , University of Tübingen&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Science and industry make extensive use of simulations to model the world. However,
conventional statistical inference is often inapplicable to detailed simulation models because their
associated likelihood functions are intractable. In this talk, I discuss how simulation-based
inference (SBI) addresses this problem, with an emphasis on applications to biophysical models
of neural dynamics. I highlight SBI’s potential to close the gap between data-driven and theory-
driven models in neuroscience. Furthermore, I present our recently-introduced, first-ever
benchmark of SBI that compares algorithms in a transparent and reproducible way, explaining
different approaches, metrics for principled comparisons, key findings, and open challenges.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt;  &lt;br /&gt;
Jan-Matthis Lückmann is currently finishing his PhD in Computer Science at the University of
Tübingen, advised by Prof. Jakob Macke. Jan-Matthis’ research interests are at the intersection of
machine learning and computational neuroscience. His expertise lies in simulation-based
inference and its applications to mechanistic models. Jan-Matthis’ work includes the proposal of
fast and flexible inference algorithms based on neural density estimation and their applications to
biophysical models in neuroscience. Most recently, he introduced the first-ever benchmark for the
rapidly developing field of simulation-based inference.&lt;/p&gt;

&lt;p&gt;This meeting was not recorded.&lt;/p&gt;

</content>

			
				<category term="colloquium" />
			
			
				<category term="colloquium" />
			

			<published>2022-02-07T00:00:00+01:00</published>
		</entry>
	
		<entry>
			<id>https://ai4science-amsterdam.github.io//colloquium/andrew-ferguson/</id>
			<title>Andrew Ferguson</title>
			<link href="https://ai4science-amsterdam.github.io//colloquium/andrew-ferguson/" rel="alternate" type="text/html" title="Andrew Ferguson" />
			<updated>2022-01-18T00:00:00+01:00</updated>

			
				
				<author>
					
						<name>Jim Boelrijk</name>
					
					
					
				</author>
			
			<summary>Ultra-fast molecular simulators and data-driven protein design</summary>
			<content type="html" xml:base="https://ai4science-amsterdam.github.io//colloquium/andrew-ferguson/">&lt;h4 id=&quot;ultra-fast-molecular-simulators-and-data-driven-protein-design&quot;&gt;Ultra-fast molecular simulators and data-driven protein design&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;../../people/AndrewFerguson.jpeg&quot; alt=&quot;AndrewFerguson&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Andrew Ferguson&lt;/strong&gt;, Pritzker School of Molecular Engineering, University of Chicago&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Data-driven modeling and deep learning present powerful tools that are opening up new paradigms and opportunities in the understanding, discovery, and design of soft and biological materials. In this talk, I will first describe an approach based on latent space simulators to learn ultra-fast surrogate models of protein folding by stacking three specialized deep learning networks to (i) encode a molecular system into a slow latent space, (ii) propagate dynamics in this latent space, and (iii) generatively decode a synthetic molecular trajectory. I will then describe our recent applications of deep representational learning to expose the sequence-function relationship within homologous protein families and to use these principles for the data-driven design and experimental testing of synthetic proteins with new and/or elevated function.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Andrew Ferguson is an Associate Professor and Deputy Dean for Equity, Diversity, and Inclusion at the Pritzker School of Molecular Engineering at the University of Chicago. He received an M.Eng. in Chemical Engineering from Imperial College London in 2005, and a Ph.D. in Chemical and Biological Engineering from Princeton University in 2010. From 2010 to 2012 he was a Postdoctoral Fellow of the Ragon Institute of MGH, MIT, and Harvard in the Department of Chemical Engineering at MIT. He commenced his independent career as an Assistant Professor of Materials Science and Engineering at the University of Illinois at Urbana-Champaign in August 2012 and was promoted to Associate Professor of Materials Science and Engineering and Chemical and Biomolecular Engineering in January 2018. He joined the Pritzker School of Molecular Engineering in July 2018. His research uses theory, simulation, and machine learning to understand and design self-assembling materials, macromolecular folding, and antiviral therapies. He is the recipient of a 2020 Dreyfus Foundation Award for Machine Learning in the Chemical Sciences and Engineering, 2018/19 Junior Moulton Medal of the Institution of Chemical Engineers, 2017 UIUC College of Engineering Dean’s Award for Excellence in Research, 2016 AIChE CoMSEF Young Investigator Award for Modeling &amp;amp; Simulation, 2015 ACS OpenEye Outstanding Junior Faculty Award, 2014 NSF CAREER Award, 2014 ACS PRF Doctoral New Investigator, and was named the Institution of Chemical Engineers North America 2013 Young Chemical Engineer of the Year. He is the co-founder of the protein engineering company Evozyne, Inc. (&lt;a href=&quot;www.evozyne.com&quot;&gt;www.evozyne.com&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;radius button small&quot; href=&quot;https://drive.google.com/file/d/1KJt-T8hqy77dDNPrxViiCPbusLHW0Vp5/view?usp=sharing&quot;&gt;Watch Back ›&lt;/a&gt;&lt;/p&gt;

</content>

			
				<category term="colloquium" />
			
			
				<category term="colloquium" />
			

			<published>2022-01-18T00:00:00+01:00</published>
		</entry>
	
		<entry>
			<id>https://ai4science-amsterdam.github.io//colloquium/atilim-gunes-baydin/</id>
			<title>Atılım Güneş Baydin</title>
			<link href="https://ai4science-amsterdam.github.io//colloquium/atilim-gunes-baydin/" rel="alternate" type="text/html" title="Atılım Güneş Baydin" />
			<updated>2021-12-21T00:00:00+01:00</updated>

			
				
				<author>
					
						<name>Jim Boelrijk</name>
					
					
					
				</author>
			
			<summary>Probabilistic Programming in Scientific Simulators</summary>
			<content type="html" xml:base="https://ai4science-amsterdam.github.io//colloquium/atilim-gunes-baydin/">&lt;h4 id=&quot;probabilistic-programming-in-scientific-simulators&quot;&gt;Probabilistic Programming in Scientific Simulators&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;../../people/AtilimBayden.jpeg&quot; alt=&quot;AtilimBayden&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Atılım Güneş Baydin&lt;/strong&gt;, University of Oxford&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Probabilistic programming languages (PPLs) allow us to specify complex generative models as computer code and perform Bayesian inference in these models automatically. However, applications of these languages in the science domain remain limited because of the impracticability of rewriting complex scientific simulators in a PPL, the computational cost of inference, and the lack of scalable implementations. To address these, we present a novel probabilistic programming framework that couples directly to existing scientific simulators through a cross-platform probabilistic execution protocol and provides Markov chain Monte Carlo (MCMC) and deep-learning-based inference compilation (IC) engines for tractable inference. The talk will cover the technical details of how a PPL system can be coupled to any given simulator so that these two sides can be (1) implemented in different programming languages and (2) executed in separate processes and possibly on separate machines across a network connection. We show examples of the approach in particle physics, epidemiology, and simulation of composite materials. We show how the simulator can be replaced with a fast deep-learning-based surrogate making use of the probabilistic execution protocol and retaining the original address structure of the simulator. We also talk about technical challenges of repurposing simulators as probabilistic programs, such as dealing with very large numbers of latent variables and nested stochastic subprocedures.&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;radius button small&quot; href=&quot;https://drive.google.com/file/d/1gc3Ca9qycyHnlHciE-ZTGoCsolhGsvuW/view?usp=sharing&quot;&gt;Watch Back ›&lt;/a&gt;&lt;/p&gt;

</content>

			
				<category term="colloquium" />
			
			
				<category term="colloquium" />
			

			<published>2021-12-21T00:00:00+01:00</published>
		</entry>
	
		<entry>
			<id>https://ai4science-amsterdam.github.io//colloquium/chris-rackauckas/</id>
			<title>Chris Rackauckas</title>
			<link href="https://ai4science-amsterdam.github.io//colloquium/chris-rackauckas/" rel="alternate" type="text/html" title="Chris Rackauckas" />
			<updated>2021-11-23T00:00:00+01:00</updated>

			
				
				<author>
					
						<name>Jim Boelrijk</name>
					
					
					
				</author>
			
			<summary>The Interplay of Science-Guided AI and Differentiable Simulation</summary>
			<content type="html" xml:base="https://ai4science-amsterdam.github.io//colloquium/chris-rackauckas/">&lt;h4 id=&quot;the-interplay-of-science-guided-ai-and-differentiable-simulation&quot;&gt;The Interplay of Science-Guided AI and Differentiable Simulation&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;../../people/ChrisRackauckas.jpeg&quot; alt=&quot;ChrisRackauckas&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Chris Rackauckas&lt;/strong&gt;, Applied Mathematics Instructor at the Massachusetts Institute of Technology&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Science-Guided AI or Scientific machine learning (SciML) methods allow for the automatic discovery of mechanistic models by infusing neural network training into the simulation process. In this talk we will start by showcasing some of the ways that SciML is being used, from discovery of extrapolatory epidemic models to nonlinear mixed effects models in pharmacology. From there, we will discuss some of the increasingly advanced computational techniques behind the training process, focusing on the numerical issues involved in handling differentiation of highly stiff and chaotic systems. The viewers will leave with an understanding of how compiler techniques are being infused into the simulation stack to increasingly automate the process of developing mechanistic models.&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;radius button small&quot; href=&quot;https://drive.google.com/file/d/14wWf4SuFOYf3vFLJ814m563LdI01gxTl/view?usp=sharing&quot;&gt;Watch Back ›&lt;/a&gt;&lt;/p&gt;

</content>

			
				<category term="colloquium" />
			
			
				<category term="colloquium" />
			

			<published>2021-11-23T00:00:00+01:00</published>
		</entry>
	
		<entry>
			<id>https://ai4science-amsterdam.github.io//colloquium/janwillem-vandemeent/</id>
			<title>Jan-Willem van de Meent</title>
			<link href="https://ai4science-amsterdam.github.io//colloquium/janwillem-vandemeent/" rel="alternate" type="text/html" title="Jan-Willem van de Meent" />
			<updated>2021-11-09T00:00:00+01:00</updated>

			
				
				<author>
					
						<name>Jim Boelrijk</name>
					
					
					
				</author>
			
			<summary>Compositional Inference in Probabilistic Programs</summary>
			<content type="html" xml:base="https://ai4science-amsterdam.github.io//colloquium/janwillem-vandemeent/">&lt;h4 id=&quot;compositional-inference-in-probabilistic-programs&quot;&gt;Compositional Inference in Probabilistic Programs&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;../../people/JanWillemVanDeMeent.jpeg&quot; alt=&quot;JanWillem&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Jan-Willem van de Meent&lt;/strong&gt;, Associate Professor (UHD), AMLab, University of Amsterdam&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Deep probabilistic programming systems combine the principles of deep learning with the principles of probabilistic modeling. The user programmatically specifies a deep generative model (a neural mapping from latent variables to data), along with a corresponding inference model (a neural mapping from data to latent variables), which together can be trained using stochastic gradient descent with little or no supervision.&lt;/p&gt;

&lt;p&gt;In this talk, I will discuss recent innovations in training deep probabilistic programs by combining techniques from variational inference and importance sampling. For many years, deep generative models were typically trained by maximizing a reparameterized lower bound, as is done in variational autoencoders. However, this approach can fail to converge to a meaningful representation in more structured problems, such as tasks the involve reasoning about shared features for a small batch of inputs. I will discuss how we can overcome these difficulties, using variational methods that learn proposals for importance samplers, as well as a programming abstractions for high-level specification of such methods in probabilistic programming systems.&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;radius button small&quot; href=&quot;https://drive.google.com/file/d/12QHeLakkguFd9mLA9I2ylcqVeUEyVS2R/view?usp=sharing&quot;&gt;Watch Back ›&lt;/a&gt;&lt;/p&gt;

</content>

			
				<category term="colloquium" />
			
			
				<category term="colloquium" />
			

			<published>2021-11-09T00:00:00+01:00</published>
		</entry>
	
		<entry>
			<id>https://ai4science-amsterdam.github.io//colloquium/saer-samanipour/</id>
			<title>Saer Samanipour</title>
			<link href="https://ai4science-amsterdam.github.io//colloquium/saer-samanipour/" rel="alternate" type="text/html" title="Saer Samanipour" />
			<updated>2021-08-31T00:00:00+02:00</updated>

			
				
				<author>
					
						<name>Jim Boelrijk</name>
					
					
					
				</author>
			
			<summary>Machine Learning and High Resolution Mass Spectrometry</summary>
			<content type="html" xml:base="https://ai4science-amsterdam.github.io//colloquium/saer-samanipour/">&lt;p&gt;&lt;img src=&quot;../../people/SaerSamanipour2.jpeg&quot; alt=&quot;SaerSamanipour&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Saer Samanipour&lt;/strong&gt;, Assistant Professor at the University of Amsterdam and honorary research fellow at the UQ, Australia&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;High resolution mass spectrometry is one of the main tools for chemical characterization of complex samples. The samples analyzed with this instrument result into large datasets comprising of up to 8.0e12 variables that could potentially carry crucial structural information about the sample chemistry. At the same time there are different sources of signal redundancy in such datasets. In this talk I will present two case studies where machine learning enables the removal of the data redundancy without any information loss. The first case study will discuss the seamless conversion from the profile mode to centroided and vice versa. In this case, we developed a self adjusting centroiding algorithm to detect and extract the meaningful information in such complex datasets. Additionally, a regression model was developed to convert the extracted information to the raw data. The second case study, is related to the development of a stochastic classification model to detect the isotopic signal in the mass spectra and therefore increase the level of confidence in the generated identifications.&lt;/p&gt;

&lt;!-- 
&lt;a class=&quot;radius button small&quot; href=&quot;https://drive.google.com/file/d/1IZsF5hh3TPpZmp9DtmgYR6JJNX6vZsoL/view?usp=sharing&quot;&gt;Watch Back ›&lt;/a&gt;
--&gt;
</content>

			
				<category term="colloquium" />
			
			
				<category term="colloquium" />
			

			<published>2021-08-31T00:00:00+02:00</published>
		</entry>
	
		<entry>
			<id>https://ai4science-amsterdam.github.io//colloquium/pratyush-tiwary/</id>
			<title>Pratyush Tiwari</title>
			<link href="https://ai4science-amsterdam.github.io//colloquium/pratyush-tiwary/" rel="alternate" type="text/html" title="Pratyush Tiwari" />
			<updated>2021-06-22T00:00:00+02:00</updated>

			
				
				<author>
					
						<name>Jim Boelrijk</name>
					
					
					
				</author>
			
			<summary>Can artificial intelligence help understand and predict molecular dynamics?</summary>
			<content type="html" xml:base="https://ai4science-amsterdam.github.io//colloquium/pratyush-tiwary/">&lt;p&gt;&lt;img src=&quot;../../people/PratyushTiwari.png&quot; alt=&quot;PratyushTiwari&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Pratyush Tiwary&lt;/strong&gt;, Asst. Prof University of Maryland, Washington DC&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;
The ability to rapidly learn from high-dimensional data to make reliable predictions about the future is crucial in many contexts. This could be a fly avoiding predators, or the retina processing terabytes of data guiding complex human actions. Modern day artificial intelligence (AI) aims to mimic this fidelity and has been successful in many domains of life. It is tempting to ask if AI could also be used to understand and predict the dynamics of complex molecules with millions of atoms. In this talk I will show that certain flavors of AI can indeed help us understand generic molecular dynamics and also predict it even in situations with arbitrary long memories. However this requires close integration of AI with old and new ideas in statistical mechanics. I will talk about such methods developed by my group (1-3). I will demonstrate the methods on different problems, where we predict mechanisms at timescales much longer than milliseconds while keeping all-atom/femtosecond resolution. These include ligand dissociation from flexible protein/RNA and crystal nucleation with competing polymorphs. I will conclude by discussing some generic challenges and  solutions regarding reliability, interpretability and extrapolative powers of AI when used to guide and complement simulations and perhaps even experiments in chemistry.&lt;/p&gt;

&lt;p&gt;References:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Wang, Y., Ribeiro, J.M.L. &amp;amp; Tiwary, P. Past–future information bottleneck for sampling molecular reaction coordinate simultaneously with thermodynamics and kinetics. Nat. Commun. 10, 3573 (2019).&lt;/li&gt;
  &lt;li&gt;Tsai, S.T, Kuo, E.J. &amp;amp; Tiwary, P.  Learning Molecular Dynamics with Simple Language Model built upon Long Short-Term Memory Neural Network. Nat. Commun. 11, 5115 (2020).&lt;/li&gt;
  &lt;li&gt;Wang, Y., Ribeiro, J.M.L. and Tiwary, P. Machine learning approaches for analyzing and enhancing molecular dynamics simulations. Curr. Op. Sruc. Bio., 61, 139 (2020).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a class=&quot;radius button small&quot; href=&quot;https://drive.google.com/file/d/1IZsF5hh3TPpZmp9DtmgYR6JJNX6vZsoL/view?usp=sharing&quot;&gt;Watch Back ›&lt;/a&gt;&lt;/p&gt;

</content>

			
				<category term="colloquium" />
			
			
				<category term="colloquium" />
			

			<published>2021-06-22T00:00:00+02:00</published>
		</entry>
	
</feed>