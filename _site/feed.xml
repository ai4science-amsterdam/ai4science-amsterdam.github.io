<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="http://127.0.0.1:4000//assets/xslt/rss.xslt" ?>
<?xml-stylesheet type="text/css" href="http://127.0.0.1:4000//assets/css/rss.css" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>AI4Science Lab</title>
		<description>The AI4Science Lab is an initiative supported by the Faculty of Science (FNWI) at the University of Amsterdam and located in the Informatics Institute (IvI). The AI4Science Lab is also connected to AMLAB, the Amsterdam Machine Learning Lab.
We develop and use machine learning techniques to discover patterns in data streams produced by experiments in a wide variety of scientific fields, ranging from ecology to molecular biology and from chemistry to astrophysics.</description>
		<link>http://127.0.0.1:4000//</link>
		<atom:link href="http://127.0.0.1:4000//feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Jacobus Dijkman</title>
				<link>http://127.0.0.1:4000//projects/jacobus-dijkman2/</link>
				<pubDate>Sun, 20 Apr 2025 00:00:00 +0200</pubDate>
				<description>&lt;h4 id=&quot;deep-gaussian-markov-random-fields&quot;&gt;Deep Gaussian Markov Random Fields&lt;/h4&gt;

&lt;p&gt;Date: 25-10-2022 14:00-1500 Central European Summer time&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../people/FredrikLindsten.png&quot; alt=&quot;FredrikLindsten&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Fredrik Lindsten&lt;/strong&gt;, Linköping University&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Machine learning methods on graphs are relevant for many application domains due to their ability to model complex dependencies and structures. Gaussian Markov Random Fields (GMRFs) provide a principled way to define Gaussian models on graphs by utilizing their sparsity structure. In this talk I will show how we can use graph neural networks (GNNs) and convolutional neural networks (CNNs) do design scalable and flexible GMRFs. Starting with lattice graphs, we establish a formal connection between CNNs and GMRFs, by showing that common GMRFs are special cases of a generative model where the inverse mapping from data to latent variables is given by a 1-layer linear CNN. This connection allows us to generalize GMRFs to multi-layer CNN architectures, effectively increasing the order of the corresponding GMRF in a way which has favorable computational scaling. I will also discuss how this Deep GMRF can be generalized to arbitrary graphs using a specialized GNN layer. Well-established tools, such as autodiff and variational inference, can be used for simple and efficient inference and learning of the Deep GMRF, and for a Gaussian likelihood, close to exact Bayesian inference is available for the latent field. I demonstrate the flexibility of the proposed model and show that it compares favorably to other methods, both Bayesian and deep-learning-based, on spatial and non-spatial data.&lt;/p&gt;

&lt;p&gt;Joint work with Joel Oskarsson (LiU) and Per Sidén (LiU/Qualcomm Arriver)&lt;/p&gt;

&lt;p&gt;Papers:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2002.07467&quot;&gt;Deep Gaussian Markov Random Fields&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2206.05032&quot;&gt;Scalable Deep Gaussian Markov Random Fields for General Graphs&lt;/a&gt;&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://127.0.0.1:4000//projects/jacobus-dijkman2/</guid>
			</item>
		
			<item>
				<title>Aaditya Ramdas</title>
				<link>http://127.0.0.1:4000//colloquium/aaditya-ramdas/</link>
				<pubDate>Tue, 14 Mar 2023 00:00:00 +0100</pubDate>
				<description>&lt;h4 id=&quot;conformal-prediction-under-distribution-shift&quot;&gt;Conformal prediction under distribution shift&lt;/h4&gt;

&lt;p&gt;Date: 14-03-2023 14:00-1500 Central European Winter time&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;....//people/AadityaRamdas.png&quot; alt=&quot;Aaditya Ramdas&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Aaditya Ramdas&lt;/strong&gt;, Carnegie Mellon University&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Conformal prediction is a modern technique for quantifying predictive uncertainty for arbitrary ML models. Its validity relies on the assumptions of exchangeability of the data, and symmetry of the given model fitting algorithm as a function of the data. However, exchangeability is often violated when predictive models are deployed in practice, and in such settings, we might want to use an algorithm that treats observations asymmetrically (eg: upweighting more recent observations).This paper proposes a new methodology to deal with both aspects: we use weighted quantiles to introduce robustness against distribution drift, and design a new technique to allow for asymmetric algorithms. Our algorithms are provably robust, with substantially less loss of coverage under distribution drift or shift, while also reducing to the same algorithm and coverage guarantees as existing conformal prediction methods if the data points are in fact exchangeable.This is joint work with Rina Barber, Emmanuel Candes and Ryan Tibshirani. A preprint is at &lt;a href=&quot;https://arxiv.org/abs/2202.13415&quot;&gt;https://arxiv.org/abs/2202.13415&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Aaditya Ramdas (PhD, 2015) is an assistant professor at Carnegie Mellon University, in the Departments of Statistics and Machine Learning. He was a postdoc at UC Berkeley (2015–2018) and obtained his PhD at CMU (2010–2015), receiving the Umesh K. Gavaskar Memorial Thesis Award. Aaditya was an inaugural winner of the COPSS Leadership Award, and a recipient of the 2021 Bernoulli New Researcher Award. His work is supported by an NSF CAREER Award, an Adobe Faculty Research Award (2020), a Google Research Scholar award (2022), amongst others. He was a CUSO lecturer in 2022, and will be a Lunteren lecturer in 2023. Aaditya’s main theoretical and methodological research interests include post-selection inference (interactive, structured, online, post-hoc control of false decision rates, etc), game-theoretic statistics (sequential uncertainty quantification, confidence sequences, always-valid p-values, safe anytime-valid inference, e-processes, supermartingales, e-values, etc), and distribution-free black-box predictive inference (conformal prediction, calibration, etc). His areas of applied interest include privacy, neuroscience, genetics and auditing, and his group’s work has received multiple best paper awards.&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://127.0.0.1:4000//colloquium/aaditya-ramdas/</guid>
			</item>
		
			<item>
				<title>Fredrik Lindsten</title>
				<link>http://127.0.0.1:4000//colloquium/fredrik-lindsten/</link>
				<pubDate>Tue, 25 Oct 2022 00:00:00 +0200</pubDate>
				<description>&lt;h4 id=&quot;deep-gaussian-markov-random-fields&quot;&gt;Deep Gaussian Markov Random Fields&lt;/h4&gt;

&lt;p&gt;Date: 25-10-2022 14:00-1500 Central European Summer time&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../people/FredrikLindsten.png&quot; alt=&quot;FredrikLindsten&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Fredrik Lindsten&lt;/strong&gt;, Linköping University&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Machine learning methods on graphs are relevant for many application domains due to their ability to model complex dependencies and structures. Gaussian Markov Random Fields (GMRFs) provide a principled way to define Gaussian models on graphs by utilizing their sparsity structure. In this talk I will show how we can use graph neural networks (GNNs) and convolutional neural networks (CNNs) do design scalable and flexible GMRFs. Starting with lattice graphs, we establish a formal connection between CNNs and GMRFs, by showing that common GMRFs are special cases of a generative model where the inverse mapping from data to latent variables is given by a 1-layer linear CNN. This connection allows us to generalize GMRFs to multi-layer CNN architectures, effectively increasing the order of the corresponding GMRF in a way which has favorable computational scaling. I will also discuss how this Deep GMRF can be generalized to arbitrary graphs using a specialized GNN layer. Well-established tools, such as autodiff and variational inference, can be used for simple and efficient inference and learning of the Deep GMRF, and for a Gaussian likelihood, close to exact Bayesian inference is available for the latent field. I demonstrate the flexibility of the proposed model and show that it compares favorably to other methods, both Bayesian and deep-learning-based, on spatial and non-spatial data.&lt;/p&gt;

&lt;p&gt;Joint work with Joel Oskarsson (LiU) and Per Sidén (LiU/Qualcomm Arriver)&lt;/p&gt;

&lt;p&gt;Papers:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2002.07467&quot;&gt;Deep Gaussian Markov Random Fields&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2206.05032&quot;&gt;Scalable Deep Gaussian Markov Random Fields for General Graphs&lt;/a&gt;&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://127.0.0.1:4000//colloquium/fredrik-lindsten/</guid>
			</item>
		
			<item>
				<title>Guy Wolf</title>
				<link>http://127.0.0.1:4000//colloquium/guy-wolf/</link>
				<pubDate>Tue, 11 Oct 2022 00:00:00 +0200</pubDate>
				<description>&lt;h4 id=&quot;geometry-based-data-exploration&quot;&gt;Geometry-based Data Exploration&lt;/h4&gt;
&lt;p&gt;Date: 11-10-2022 14:00-1500 Central European Summer time&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../people/GuyWolf.jpeg&quot; alt=&quot;GuyWolf.jpeg&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Guy Wolf&lt;/strong&gt;, Université de Montréal&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;High-throughput data collection technologies are becoming increasingly common in many fields, especially in biomedical applications involving single cell data (e.g., scRNA-seq and CyTOF). These introduce a rising need for exploratory analysis to reveal and understand hidden structure in the collected (high-dimensional) Big Data. A crucial aspect in such analysis is the separation of intrinsic data geometry from data distribution, as (a) the latter is typically biased by collection artifacts and data availability, and (b) rare subpopulations and sparse transitions between meta-stable states are often of great interest in biomedical data analysis. In this talk, I will show several tools that leverage manifold learning, graph signal processing, and harmonic analysis for biomedical (in particular, genomic/proteomic) data exploration, with emphasis on visualization, data generation/augmentation, and nonlinear feature extraction. A common thread in the presented tools is the construction of a data-driven diffusion geometry that both captures intrinsic structure in data and provides a generalization of Fourier harmonics on it. These, in turn, are used to process data features along the data geometry for denoising and generative purposes. Finally, I will relate this approach to the recently-proposed geometric scattering transform that generalizes Mallat’s scattering to non-Euclidean domains, and provides a mathematical framework for theoretical understanding of the emerging field of geometric deep learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt;&lt;br /&gt;
Guy Wolf is an associate professor in the Department of Mathematics and Statistics (DMS) at the Université de Montréal (UdeM), a core academic member of Mila (the Quebec AI institute), and an associate researcher with CRCHUM (the Montreal university hospital research center). He is also affiliated with the IVADO institute of data valorization. He holds an M.Sc. and a Ph.D. in computer science from Tel Aviv University. Prior to joining UdeM, he was a postdoctoral researcher (2013-2015) in the Department of Computer Science at École Normale Supérieure in Paris (France), and a Gibbs Assistant Professor (2015-2018) in the Applied Mathematics Program at Yale University. Between 2004 and 2009 he served in the Israeli Defense Forces in IT software design and development roles related to data analysis and visualization. His research focuses on manifold learning and geometric deep learning for exploratory data analysis, including methods for dimensionality reduction, visualization, denoising, data augmentation, and coarse graining. Further, he is particularly interested in biomedical data exploration applications of such methods, e.g., in single cell genomics/proteomics and neuroscience.&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://127.0.0.1:4000//colloquium/guy-wolf/</guid>
			</item>
		
			<item>
				<title>Michele Ceriotti</title>
				<link>http://127.0.0.1:4000//colloquium/michele-ceriotti/</link>
				<pubDate>Tue, 05 Jul 2022 00:00:00 +0200</pubDate>
				<description>&lt;h4 id=&quot;a-unified-theory-of-atom-cloud-representations-for-machine-learning&quot;&gt;A unified theory of atom cloud representations for machine learning&lt;/h4&gt;

&lt;p&gt;Date: 05-07-2022 14:00-1500 Central European Summer time&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../people/MicheleCeriotti.jpeg&quot; alt=&quot;MicheleCeriotti.jpeg&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Michele Ceriotti&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Simulations of matter at the atomic scale are precious to provide a mechanistic understanding of chemical processes, and to design molecules and materials with predictive accuracy. As with many fields of science, machine learning have become an essential part of the modeling toolbox, with many frameworks having become well-established, and many more being developed in new research directions. The most effective frameworks incorporate fundamental physical principles, such as symmetry, locality, and hierarchical decompositions of the interactions between atoms, in the construction of the ML model. I will discuss a general framework that unifies several of the most recent developments in the field, including the representation of structures in terms of systematically-convergent atom-centered correlations of the neighbor density, as well as equivariant message-passing schemes that build automatically descriptors with equivalent information content. I will discuss a few examples of the implications of these fundamental findings, for both chemical machine learning and in general for problems that require a description of three-dimensional objects in terms of point clouds, and present some examples that highlight the limitations of some common approaches and point to strategies to overcome them.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bio:&lt;/strong&gt;&lt;br /&gt;
Michele Ceriotti received his Ph.D. in Physics from ETH Zürich. He spent three years in Oxford as a Junior Research Fellow at Merton College. Since 2013 he leads the laboratory for Computational Science and Modeling, in the institute of Materials at EPFL, that focuses on method development for atomistic materials modeling based on statistical mechanics and machine learning.&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;radius button small&quot; href=&quot;https://drive.google.com/file/d/1piVbnetRwbMxMFyVIgoq1cOvAw3BlqBP/view?usp=sharing&quot;&gt;Watch Back ›&lt;/a&gt;&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://127.0.0.1:4000//colloquium/michele-ceriotti/</guid>
			</item>
		
			<item>
				<title>Peter Grünwald</title>
				<link>http://127.0.0.1:4000//colloquium/peter-grunwald/</link>
				<pubDate>Tue, 21 Jun 2022 00:00:00 +0200</pubDate>
				<description>&lt;h4 id=&quot;e-is-the-new-p-evidence-and-optional-continuation&quot;&gt;E is the New P: Evidence and Optional Continuation&lt;/h4&gt;

&lt;p&gt;Date: 21-06-2022 14:00-1500 Central European Summer time&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../people/PeterGrunwald.jpeg&quot; alt=&quot;PeterGrunwald.jpeg&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Peter Grünwald&lt;/strong&gt;, CWI&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;How much evidence do the data give us about one hypothesis versus another? The standard way to measure evidence is still the p-value, despite a myriad of problems surrounding it. We present the E-value, a recently popularized notion of evidence which overcomes some of these issues. While E-values have lain dormant until 2019, their use has recenty exploded - we just had a one-week workshop (‘SAVI’ - safe anytime-valid inference) with attendees from netflix, booking (A/B testing), clinical trial design and meta-analysis.
In simple cases, the E-value coincides with the Bayes factor, the notion of evidence preferred by Bayesians. But if the null is composite or nonparametric, or an alternative cannot be explicitly formulated, E-values and Bayes factors become distinct. Unlike the Bayes factor, E-values allow for tests with strict ‘ classical’ Type-I error control under optional continuation and combination of data from different sources. They are also the basic building blocks of anytime-valid confidence intervals that remain valid under optional stopping.&lt;/p&gt;

&lt;p&gt;Note: this meeting was performed in person and was not recorded.&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://127.0.0.1:4000//colloquium/peter-grunwald/</guid>
			</item>
		
			<item>
				<title>Wujie Wang</title>
				<link>http://127.0.0.1:4000//colloquium/wujie-wang/</link>
				<pubDate>Tue, 07 Jun 2022 00:00:00 +0200</pubDate>
				<description>&lt;h4 id=&quot;generative-coarse-graining-of-molecular-conformations&quot;&gt;Generative Coarse-Graining of Molecular Conformations&lt;/h4&gt;

&lt;p&gt;Date: 07-06-2022 14:00-1500 Central European Summer time&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../people/WujieWang.jpeg&quot; alt=&quot;WujieWang&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Wujie Wang&lt;/strong&gt;, MIT&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Coarse-graining (CG) of molecular simulations simplifies the particle representation by grouping selected atoms into pseudo-beads and therefore drastically accelerates simulation. However, such CG procedure induces information losses, which makes accurate backmapping, i.e., restoring finegrained (FG) coordinates from CG coordinates, a long-standing challenge. Inspired by the recent progress in generative models and equivariant networks, we propose a novel model that rigorously embeds the vital probabilistic nature and geometric consistency requirements of the backmapping transformation. Our model encodes the FG uncertainties into an invariant latent space and decodes them back to FG geometries via equivariant convolutions. To standardize the evaluation of this domain, we further provide three comprehensive benchmarks based on molecular dynamics trajectories. Extensive experiments show that our approach always recovers more realistic structures and outperforms existing data-driven methods with a significant margin.&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;radius button small&quot; href=&quot;https://drive.google.com/file/d/1nvc1Gr9vJ-NGJkWcPmuRKEwG1o5Wwvbe/view?usp=sharing&quot;&gt;Watch Back ›&lt;/a&gt;&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://127.0.0.1:4000//colloquium/wujie-wang/</guid>
			</item>
		
			<item>
				<title>Francesca Grisoni</title>
				<link>http://127.0.0.1:4000//colloquium/francesca-grisoni/</link>
				<pubDate>Tue, 24 May 2022 00:00:00 +0200</pubDate>
				<description>&lt;h4 id=&quot;harnessing-artificial-intelligence-for-de-novo-drug-design&quot;&gt;Harnessing artificial intelligence for de novo drug design&lt;/h4&gt;

&lt;p&gt;Date: 24-05-2022 14:00-1500 Central European Summer time&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../people/FrancescaGrisoni.jpeg&quot; alt=&quot;FrancescaGrisoni&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Francesca Grisoni&lt;/strong&gt;, Eindhoven University of Technology&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Designing innovative molecules with the desired bioactivity is fundamentally a low-data problem. In fact, while the chemical universe is estimated to contain 1023 to 10100 small molecules, humans have only discovered 104 drugs. Recent advances in deep learning have allowed for a more efficient use of available information in low-data regimes. Such technological breakthroughs have now permeated the drug discovery domain, leading to some of the first bioactive molecules designed by AI without the need of human-engineered rules. In this talk, I will focus on a particular instance of generative deep learning – the so-called chemical language models – and how they can be leveraged to accelerate de novo drug design.&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;radius button small&quot; href=&quot;https://drive.google.com/file/d/1cfMSNVY1tSrMphtbrbV91YLvXj91cure/view?usp=sharing&quot;&gt;Watch Back ›&lt;/a&gt;&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://127.0.0.1:4000//colloquium/francesca-grisoni/</guid>
			</item>
		
			<item>
				<title>Maximilian Dax</title>
				<link>http://127.0.0.1:4000//colloquium/maximillian-dax/</link>
				<pubDate>Tue, 26 Apr 2022 00:00:00 +0200</pubDate>
				<description>&lt;h4 id=&quot;titlereal-time-gravitational-wave-science-with-neural-posterior-estimation&quot;&gt;Title:Real-Time Gravitational Wave Science with Neural Posterior Estimation&lt;/h4&gt;

&lt;p&gt;Date: 26-04-2022 11:00-1200 Central European Summer time&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../people/MaximilianDax.jpeg&quot; alt=&quot;MaximilianDax&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Maximilian Dax&lt;/strong&gt;, PhD Student at the Max Planck Institute for Intelligent Systems&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Inferring astrophyscial parameters from gravitational wave (GW) measurements is a central task in GW analysis. Standard inference methods, based e.g. on Markov chain Monte Carlo (MCMC), require days of computation for the analysis of a single GW event. In this talk I present our new approach DINGO that reduces this inference time to 20 seconds per event by using conditional normalizing flows. I then explain how physical symmetries can be used to enhance the accuracy of the inference networks. Finally, I demonstrate on real GW event data that our likelihood-free approach produces indistinguishable results from MCMC while being 1000 times faster.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Dax et al. Real-Time Gravitational Wave Science with Neural Posterior Estimation. Phys.Rev.Lett. 127, 241103 (2021)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dax et al. Group equivariant neural posterior estimation. ICLR 2022&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a class=&quot;radius button small&quot; href=&quot;https://drive.google.com/file/d/1Lf11UG088JvazNsdnrFSE34UlBtQk72N/view?usp=sharing&quot;&gt;Watch Back ›&lt;/a&gt;&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://127.0.0.1:4000//colloquium/maximillian-dax/</guid>
			</item>
		
			<item>
				<title>Gabriel Vivo-Truyols</title>
				<link>http://127.0.0.1:4000//colloquium/gabriel-vivo-truyols/</link>
				<pubDate>Tue, 12 Apr 2022 00:00:00 +0200</pubDate>
				<description>&lt;h4 id=&quot;title-on-the-use-of-bayesian-statistics-for-chromatography-and-mass-spectrometry-dealing-with-big-data&quot;&gt;Title: On the use of Bayesian statistics for chromatography and mass spectrometry: dealing with big data&lt;/h4&gt;

&lt;p&gt;Date: 12-04-2022 11:00-1200 Central European Summer time&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../people/GabrielVivoTruyols.jpeg&quot; alt=&quot;GabrielVivoTruyols&quot; width=&quot;100&quot; style=&quot;float: right; margin-right: 10px; border-radius:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Speaker: &lt;strong&gt;Gabriel Vivó-Truyols&lt;/strong&gt;, Principal Scientist, Tecnometrix&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Data analysis methods applied to chromatographic data, including base-line correction, peak detection, alignment and peak tracking, calibration and/or classification are a routine part of most modern analytical workflows. With the emergence of hyphenation (especially high-resolution mass spectrometry) and two-dimensional methods (e.g. LCxLC) new challenges for the data analysis are emerging.  We are witnessing a boom of the amount of data to be processed, so we can start to talk about Big Data in Analytical chemistry. Analysing these enormous and complex quantities of data becomes a tremendous challenge, especially because of the need to do it automatically. Traditionally, chromatographic data has been processed using the so-called frequentist approach. With this approach, we get just a final answer about the hypotheses we are testing, but we have no information about its probability of being true.
Contrary to the frequentist approach, Bayesian statistics offers a very interesting alternative, estimating the probabilities of the processes mentioned above. This way of thinking opens a new world of possibilities, especially in the area of automated massive data treatment. In this way, the chromatographer has no longer to “trust” the results of the data analysis, but (s)he has to decide on the different configurations that explain the data, based on the probabilities of each one.&lt;/p&gt;

&lt;p&gt;We have applied this way of thinking to a broad range of situations. One example concerns toxicological screening, in which the probabilities of a list of compounds being present in the sample, analysed with LC-MS. Using a Bayesian approach, it is easy to build up evidence about the presence/absence of a compound by taking into account adduct formation, isotope ratios, retention times and mass values, resulting in more accurate values of probability. Another example is a Bayesian view of the well-known peak tracking methods. In (traditional) peak tracking methods, peaks of the same compound are recognized in different chromatographic conditions. A Bayesian thinking approaches the problem in a probabilistic way, i.e. assigning different possibilities of peaks to the different compounds available.&lt;/p&gt;

&lt;p&gt;The use of Bayesian statistics to deal with massive data treatment in chromatography constitutes a shift in the way we think about data analysis. Basically, we are proposing to work with probabilities of hypotheses (and update them as long as more information/data is taken into account), opposed to deliver the final answer to the user.&lt;/p&gt;

&lt;p&gt;&lt;a class=&quot;radius button small&quot; href=&quot;https://drive.google.com/file/d/1vbIfaJKXQ4mx1cfch8zX_CuRfuVGhATB/view?usp=sharing&quot;&gt;Watch Back ›&lt;/a&gt;&lt;/p&gt;

</description>
				<guid isPermaLink="true">http://127.0.0.1:4000//colloquium/gabriel-vivo-truyols/</guid>
			</item>
		
	</channel>
</rss>
